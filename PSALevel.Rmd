---
title: "PSALevel - Regressão linear"
author: "Wesley Nunes Marques Torres"
date: "April 01, 2016"
output: html_document
---

```{r, echo=FALSE}
library(dplyr)
require(reshape2)
require(ggplot2)
library(corrplot)
require(caret)

dados <- read.table("~/workspaceR/LinearRegression/data/prostate.data")
```

## Objetivo da análise

Prever o nível do PSA em pacientes através de uma regressão linear.

## Um pouco sobre os dados

Temos para análise um dataset com 97 observações com 8 variáveis preditoras, 1 variável para especificar se é treino ou não e 1 variável resposta. Abaixo podemos verificar um pouco sobre a descrição de cada variável e seu tipo:

```{r}
dim(dados)
str(dados)
```

Ao sumarizar os dados, podemos verificar que há uma boa consistência nos dados e que não se tem alguma discrepância, mas com um boxsplot podemos identificar outliers, mas que neste caso, não irá nos interessar;

```{r}
summary(dados)
boxplot(dados, main="Boxsplot", xlab="Variables", ylab="Count")
```

## Scatter plot dos dados

Podemos verificar o relacionamento entre as variáveis com a variável resposta através de um scatter plot. Abaixo, o que chama atenção é poder avaliar a dispersão entre as variáveis e mais precisamente a da variável resposta(lpsa)

```{r}
plot(dados, main="Scatterplot", pch=1)
```

## Análise de correlação

Como se pode analisar no gráfico abaixo, a correlação com sí próprio é redundante e logicamente, tem um valor alto. A correlação será de suma importância para escola dos preditores da variável resposta. Com o plot abaixo podemos perceber que temos ótimos candidatos para preditores.

```{r}
correlationMatrix <- cor(dados)
corrplot(correlationMatrix, method="number", type="lower", order="hclust")
```

## Separando dados para treino

Como foi dado, existe um campo para nos dizer se uma amostra é do tipo treino ou teste. Abaixo, vamos separar esses dados em diferentes dataframes para realizar o treino do modelo de forma correta.

```{r}
train <- filter(dados,train)
test <- filter(dados,!train)
```

#Treinando meu modelo

Para realizar o treino, precisamos verificar quais preditores são melhores para se ter um modelo com a melhor acurácia possível. Para isso, a princípio, uma das melhores formas de se realizar o treino é escolhendo preditores com um alto valor de correlação com a variável resposta. Acima, temos os valores das correlações entre as variáveis, e com base nisso, foram escolhidas as variáveis: lcavol, svi e lcp. 

```{r}
lm <- lm(lpsa ~ lcavol+svi+lcp,data = train)
```

Temos agora um modelo e basta verificar a acurácia desse modelo


```{r}
lm
summary(lm)
```

## Realizando a previsão

```{r}
prediction <- predict(lm, select(test,lcavol, svi, lcp))
lm_prediction <- data.frame(pred = prediction, obs = test$lpsa)
ggplot(lm_prediction, aes(x = pred, y = obs)) + geom_point(alpha = 0.5, position = position_jitter(width=0.2)) + geom_abline(colour = "blue") + ggtitle("Previsão x Observado (validação)")
```

# Com os dados expostos, podemos responder as seguintes perguntas: 

> Há evidência de relação entre os preditores e a variável alvo?

Podemos identificar evidências de relação entre preditores e variável alvo analisando a correlação entre elas. Com isso, temos que as variáveis lcavol(Volume do câncer), svi(invasão das vesículas seminais) e cp(penetração capsular) são fortes candidatos para preditores que me darão uma boa acurácia no meu modelo.

> Havendo relação, quão forte é essa relação?

Como já foi mostrado no gráfico acima, mas temos os seguintes valores para representar um relação entre os preditores escolhidos e a variável resposta. Com valores de 0-1, indicando nível de correlação, de mais fraco para mais forte, temos:

* lcavol X lpsa = 0.73
* svi X lpsa = 0.57
* lcp X lpsa = 0.55

> Que variável parece contribuir mais?

Tendo como base o nível de correlação, a variável **lcavol** aparentemente possui uma maior contribuição para o modelo.

> A relação sugere um modelo de regressão linear?

```{r}
summary(lm)

ggplot(lm_prediction, aes(y = obs - pred, x = pred)) + 
  geom_point(alpha = 0.5, position = position_jitter(width=0.1)) + 
  geom_abline(slope = 0, intercept = 0, colour = "darkred")
```

Pelo gráfico de resíduo e uma sumarização dos dados, vemos que temos um grande indício para se utilizar a regressão linear. Um dos fatores é o da Mediana dos resíduos se encontrar próximo de zero e módulo do 1Q e do 3Q serem aproximados. 

Por fim, temos os valores de RMSE = 0.665, que é muito bom, pois nos diz a o erro dos valores esperados para os observados e como foi baixo, já nos diz que o uso de Regressão é uma boa opção para esse caso. Outra informação importante é o Rsquared = 58,5%, que nos diz o quando minhas variáveis explicam meu modelo. Com isso, temos os valores finais abaixo para a predição do nível do PSA em pacientes:


```{r}
round(defaultSummary(lm_prediction), digits = 3)
```


